{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.5713e-01  2.3378e+00  4e+00  2e+00  6e-16\n",
      " 1:  9.8313e-01  3.9366e+00  7e-01  7e-01  3e-15\n",
      " 2:  3.8561e+00  7.8776e+00  1e+00  4e-01  1e-13\n",
      " 3:  8.5531e+00  8.9940e+00  3e-01  4e-02  3e-14\n",
      " 4:  8.9951e+00  9.0000e+00  3e-03  5e-04  6e-14\n",
      " 5:  9.0000e+00  9.0000e+00  3e-05  5e-06  2e-14\n",
      " 6:  9.0000e+00  9.0000e+00  3e-07  5e-08  3e-14\n",
      "Optimal solution found.\n",
      "[0.99999996 0.99999998] [-3.99999989]\n",
      "[[1. 1.]] [-4.]\n",
      "Acc=1.0\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4564e+00  1.1836e+01  2e+01  2e+00  4e-15\n",
      " 1:  2.7889e+00  2.1466e+01  6e+00  1e+00  3e-15\n",
      " 2:  1.1208e+01  1.0202e+02  1e+01  9e-01  9e-14\n",
      " 3:  3.2657e+01  1.9223e+02  3e+01  8e-01  6e-13\n",
      " 4:  1.1376e+02  3.1957e+02  7e+01  6e-01  1e-12\n",
      " 5:  3.4044e+02  4.2149e+02  6e+01  2e-01  2e-12\n",
      " 6:  4.2867e+02  4.3311e+02  3e+00  9e-03  4e-12\n",
      " 7:  4.3393e+02  4.3418e+02  3e-01  6e-04  1e-11\n",
      " 8:  4.3424e+02  4.3424e+02  3e-03  6e-06  2e-11\n",
      " 9:  4.3424e+02  4.3424e+02  3e-05  6e-08  2e-11\n",
      "Optimal solution found.\n",
      "[0.01047857]\n",
      "Acc=1.0\n",
      "Passed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.5308e+00  1.1154e+01  2e+01  2e+00  2e-15\n",
      " 1:  3.3051e+00  1.8963e+01  4e+00  9e-01  1e-15\n",
      " 2:  6.7220e+00  4.8073e+01  7e+00  9e-01  2e-14\n",
      " 3:  2.3513e+01  9.7735e+01  2e+01  8e-01  9e-12\n",
      " 4:  8.4211e+01  1.5233e+02  3e+01  4e-01  9e-12\n",
      " 5:  1.5868e+02  1.6853e+02  8e+00  5e-02  1e-11\n",
      " 6:  1.6879e+02  1.6891e+02  1e-01  6e-04  3e-11\n",
      " 7:  1.6891e+02  1.6891e+02  1e-03  6e-06  3e-11\n",
      " 8:  1.6891e+02  1.6891e+02  1e-05  6e-08  2e-11\n",
      "Optimal solution found.\n",
      "[0.00609535]\n",
      "Acc=1.0\n",
      "Passed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.2744e-01  1.2343e+01  6e+01  2e+00  2e+01\n",
      " 1:  6.8634e+00  2.0108e+01  3e+01  1e+00  1e+01\n",
      " 2:  9.4544e+00  3.9302e+01  3e+01  1e+00  1e+01\n",
      " 3:  3.4940e+01  1.1080e+02  2e+01  6e-01  6e+00\n",
      " 4:  5.8114e+01  1.2868e+02  3e+01  5e-01  5e+00\n",
      " 5:  1.4039e+02  1.3820e+02  2e+01  6e-02  5e-01\n",
      " 6:  1.4776e+02  1.4775e+02  3e-01  9e-04  8e-03\n",
      " 7:  1.4786e+02  1.4786e+02  3e-03  9e-06  8e-05\n",
      " 8:  1.4786e+02  1.4786e+02  3e-05  9e-08  8e-07\n",
      " 9:  1.4786e+02  1.4786e+02  3e-07  9e-10  8e-09\n",
      "Optimal solution found.\n",
      "[0.00216811]\n",
      "Acc=1.0\n",
      "Passed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.1795e+00  2.5719e+01  5e+01  2e+00  1e+01\n",
      " 1:  5.7721e+00  3.1818e+01  3e+01  1e+00  7e+00\n",
      " 2:  1.2245e+01  9.6168e+01  3e+01  1e+00  6e+00\n",
      " 3:  4.4781e+01  2.3324e+02  6e+01  8e-01  5e+00\n",
      " 4:  1.2042e+02  3.3242e+02  9e+01  6e-01  4e+00\n",
      " 5:  3.3582e+02  4.2127e+02  6e+01  2e-01  1e+00\n",
      " 6:  4.3307e+02  4.3694e+02  4e+00  9e-03  5e-02\n",
      " 7:  4.3790e+02  4.3793e+02  4e-02  9e-05  5e-04\n",
      " 8:  4.3794e+02  4.3794e+02  4e-04  9e-07  5e-06\n",
      " 9:  4.3795e+02  4.3795e+02  4e-06  9e-09  5e-08\n",
      "Optimal solution found.\n",
      "[0.01202121]\n",
      "Acc=1.0\n",
      "Passed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.4027e-01  1.1462e+01  6e+01  2e+00  3e+01\n",
      " 1:  7.9833e+00  4.7023e+00  2e+01  8e-01  1e+01\n",
      " 2:  1.9480e+01  1.6674e+01  6e+00  8e-02  1e+00\n",
      " 3:  2.0496e+01  1.9942e+01  6e-01  2e-03  3e-02\n",
      " 4:  2.0330e+01  2.0312e+01  2e-02  4e-05  6e-04\n",
      " 5:  2.0326e+01  2.0325e+01  2e-04  4e-07  6e-06\n",
      " 6:  2.0326e+01  2.0326e+01  2e-06  4e-09  6e-08\n",
      "Optimal solution found.\n",
      "[0.00105247]\n",
      "Acc=1.0\n",
      "Passed\n"
     ]
    }
   ],
   "source": [
    "from cvxopt import solvers, matrix\n",
    "import numpy as np\n",
    "import sklearn.svm\n",
    "\n",
    "class SVM453X ():\n",
    "    def __init__ (self):\n",
    "        pass\n",
    "\n",
    "    # Expects each *row* to be an m-dimensional row vector. X should\n",
    "    # contain n rows, where n is the number of examples.\n",
    "    # y should correspondingly be an n-vector of labels (-1 or +1).\n",
    "    def fit (self, X, y):\n",
    "        \n",
    "        Xtilde = np.append(X, np.ones((X.shape[0], 1)), axis=1)\n",
    "        m, n = Xtilde.shape\n",
    "        \n",
    "        G = -1 * y.reshape(1, y.shape[0]).T * Xtilde\n",
    "        P = np.eye(n)\n",
    "        q = np.zeros(n)\n",
    "        h = np.full((m, 1), -1)\n",
    "\n",
    "        # Solve -- if the variables above are defined correctly, you can call this as-is:\n",
    "        sol = solvers.qp(matrix(P, tc='d'), matrix(q, tc='d'), matrix(G, tc='d'), matrix(h, tc='d'))\n",
    "\n",
    "        # Fetch the learned hyperplane and bias parameters out of sol['x']\n",
    "        results = np.array(sol['x'])\n",
    "        self.w = results[:-1].reshape((results[:-1].shape[0]))\n",
    "        self.b = results[-1]\n",
    "\n",
    "    # Given a 2-D matrix of examples X, output a vector of predicted class labels\n",
    "    def predict (self, x):\n",
    "        return np.sign(np.dot(x, self.w) + self.b)\n",
    "\n",
    "def test1 ():\n",
    "    # Set up toy problem\n",
    "    X = np.array([ [1,1], [2,1], [1,2], [2,3], [1,4], [2,4] ])\n",
    "    y = np.array([-1,-1,-1,1,1,1])\n",
    "\n",
    "    # Train your model\n",
    "    svm453X = SVM453X()\n",
    "    svm453X.fit(X, y)\n",
    "    print(svm453X.w, svm453X.b)\n",
    "\n",
    "    # Compare with sklearn\n",
    "    svm = sklearn.svm.SVC(kernel='linear', C=1e15)  # 1e15 -- approximate hard-margin\n",
    "    svm.fit(X, y)\n",
    "    print(svm.coef_, svm.intercept_)\n",
    "\n",
    "    acc = np.mean(svm453X.predict(X) == svm.predict(X))\n",
    "    print(\"Acc={}\".format(acc))\n",
    "\n",
    "def test2 (seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Generate random data\n",
    "    X = np.random.rand(20,3)\n",
    "    # Generate random labels based on a random \"ground-truth\" hyperplane\n",
    "    while True:\n",
    "        w = np.random.rand(3)\n",
    "        y = 2*(X.dot(w) > 0.5) - 1\n",
    "        # Keep generating ground-truth hyperplanes until we find one\n",
    "        # that results in 2 classes\n",
    "        if len(np.unique(y)) > 1:\n",
    "            break\n",
    "\n",
    "    svm453X = SVM453X()\n",
    "    svm453X.fit(X, y)\n",
    "\n",
    "    # Compare with sklearn\n",
    "    svm = sklearn.svm.SVC(kernel='linear', C=1e15)  # 1e15 -- approximate hard margin\n",
    "    svm.fit(X, y)\n",
    "    diff = np.linalg.norm(svm.coef_ - svm453X.w) + np.abs(svm.intercept_ - svm453X.b)\n",
    "    print(diff)\n",
    "\n",
    "    acc = np.mean(svm453X.predict(X) == svm.predict(X))\n",
    "    print(\"Acc={}\".format(acc))\n",
    "\n",
    "    if acc == 1 and diff < 1e-1:\n",
    "        print(\"Passed\")\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    test1()\n",
    "    for seed in range(5):\n",
    "        test2(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8557191054102763\n",
      "0.8334530188299514\n"
     ]
    }
   ],
   "source": [
    "# auc1: 0.8557191054102763\n",
    "# auc2: 0.8334530188299514\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "def bag_data(train, test, n):\n",
    "    return np.split(train, n), np.split(test, n)\n",
    "\n",
    "def bag_predictions(model, X_bags, y_bags, x_test):\n",
    "    predictions = np.empty((0, x_test.shape[0]))\n",
    "    for x_bag, y_bag in  zip(X_bags, y_bags):\n",
    "        temp_model = model\n",
    "        temp_model.fit(x_bag, y_bag)\n",
    "        prediction = temp_model.decision_function(x_test)\n",
    "        predictions = np.append(predictions, [prediction], axis = 0)\n",
    "    average_predictions = np.mean(predictions, axis = 0)\n",
    "    return average_predictions\n",
    "        \n",
    "\n",
    "# Load data\n",
    "d = pandas.read_csv('train.csv')\n",
    "y = np.array(d.target)  # Labels\n",
    "X = np.array(d.iloc[:,2:])  # Features\n",
    "\n",
    "# Split into train/test folds\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size = 0.5, random_state = 0)\n",
    "\n",
    "X_tr_bags, y_tr_bags = bag_data(X_tr, y_tr, 50)\n",
    "\n",
    "# Linear SVM\n",
    "linear_svm =  LinearSVC(random_state = 0, dual = False)\n",
    "\n",
    "# Non-linear SVM (polynomial kernel)\n",
    "poly_svm = SVC(random_state = 0, kernel = 'poly')\n",
    "\n",
    "# Apply the SVMs to the test set\n",
    "yhat1 = bag_predictions(linear_svm, X_tr_bags, y_tr_bags, X_te)\n",
    "yhat2 = bag_predictions(poly_svm, X_tr_bags, y_tr_bags, X_te)\n",
    "\n",
    "# Compute AUC\n",
    "auc1 = roc_auc_score(y_te, yhat1)\n",
    "auc2 = roc_auc_score(y_te, yhat2)\n",
    "\n",
    "print(auc1)\n",
    "print(auc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
